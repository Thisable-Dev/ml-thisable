# Sign Language
[Sign Language Dataset](https://www.kaggle.com/datasets/najmaaaaaaaaa/data-augment)

The data we use are pictures of half-bodied humans with plain backgrounds demonstrating BISINDO sign language. Using 16,800 primary images [data](https://www.kaggle.com/datasets/najmaaaaaaaaa/data-augment) with 3 labels, we do transfer learning using the MobileNet V2 model and got a validation accuracy of **90%**.

We adjust the network model and the input size so that it fits with the data we have.

![signlanguage](https://user-images.githubusercontent.com/76579538/173191442-1e2681c7-ba02-41a7-bc7c-e8cc201bb049.png)
